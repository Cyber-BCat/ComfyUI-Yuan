import numpy as np
import torch
from skimage.color import rgb2lab
from skimage.util import img_as_ubyte
from PIL import Image
import matplotlib.pyplot as plt

class lightdarkjudgment:

    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "image1": ("IMAGE", ),
                "image2": ("IMAGE", ),
                "threshold": ("FLOAT", {"default": 32.0, "min": 0.1, "max": 100.0, "step": 0.01}),
                "brightness1": ("FLOAT", {"default": 1, "min": 0.0, "max": 3, "step": 0.01}),
                "contrast1": ("FLOAT", {"default": 1, "min": 0.0, "max": 3, "step": 0.01}),
                "saturation1": ("FLOAT", {"default": 1, "min": 0.0, "max": 3, "step": 0.01}),
                "brightness2": ("FLOAT", {"default": 1, "min": 0.0, "max": 3, "step": 0.01}),
                "contrast2": ("FLOAT", {"default": 1, "min": 0.0, "max": 3, "step": 0.01}),
                "saturation2": ("FLOAT", {"default": 1, "min": 0.0, "max": 3, "step": 0.01}),
            }
        }

    RETURN_TYPES = ("IMAGE", "FLOAT", "FLOAT", "FLOAT", "FLOAT")
    RETURN_NAMES = ("IMAGE", "brightness", "contrast", "saturation", "color diff",)
    FUNCTION = "lightordarkimage"
    CATEGORY = "YuanğŸ˜º"




    def calculate_color_difference_in_diff_area(self, img1, img2):
        """
        è®¡ç®—ä¸¤å¼ å›¾åƒçš„è‰²å·®ï¼Œå¿½ç•¥é€æ˜åŒºåŸŸ

        å‚æ•°:
        img1 (numpy array): ç¬¬ä¸€å¼ å›¾åƒ
        img2 (numpy array): ç¬¬äºŒå¼ å›¾åƒ

        è¿”å›:
        float: å·®å¼‚åŒºåŸŸçš„å¹³å‡è‰²å·®
        """
        # æå–é€æ˜åº¦é€šé“
        alpha1 = img1[:, :, 3] if img1.shape[2] == 4 else np.ones(img1.shape[:2])
        alpha2 = img2[:, :, 3] if img2.shape[2] == 4 else np.ones(img2.shape[:2])
        
        # åˆ›å»ºé®ç½©ï¼Œåªä¿ç•™ä¸é€æ˜åŒºåŸŸ
        mask = (alpha1 > 0.1) & (alpha2 > 0.1)

        # è½¬æ¢å›¾åƒä¸ºLabé¢œè‰²ç©ºé—´
        img1_lab = rgb2lab(img1[:, :, :3])
        img2_lab = rgb2lab(img2[:, :, :3])

        # è®¡ç®—æ¯ä¸ªåƒç´ çš„ç»å¯¹å·®å¼‚
        diff_lab = np.abs(img1_lab - img2_lab)

        # è®¡ç®—æ•´ä½“å·®å¼‚çš„æ©ç  (å³å·®å¼‚åŒºåŸŸçš„æ©ç )
        diff_mask = np.any(diff_lab > 1, axis=-1) & mask  # é€‰æ‹©é˜ˆå€¼ä¸º1ï¼Œé˜ˆå€¼å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´

        # åœ¨æ©ç åŒºåŸŸå†…è®¡ç®—è‰²å·®
        diff_in_diff_area_lab = np.sqrt(np.sum(diff_lab ** 2, axis=-1))
        diff_in_diff_area_lab[~diff_mask] = 0  # ä»…ä¿ç•™å·®å¼‚åŒºåŸŸçš„è‰²å·®
        
        # å¦‚æœæ˜¯ä¸€ä¸ªæå°å€¼ï¼Œåˆ™è®¾ç½®ä¸º0å€¼
        if np.isnan(np.mean(diff_in_diff_area_lab[diff_mask])):
            return 0.0
        else:
            return np.mean(diff_in_diff_area_lab[diff_mask])

    def lightordarkimage(self, image1, image2, threshold, brightness1, contrast1, saturation1, brightness2, contrast2, saturation2):
        """
        æ ¹æ®è‰²å·®é˜ˆå€¼åˆ¤æ–­å¹¶è¿”å›å¯¹åº”çš„å›¾åƒåŠå…¶å±æ€§

        å‚æ•°:
        image1 (torch.Tensor): ç¬¬ä¸€å¼ å›¾åƒ
        image2 (torch.Tensor): ç¬¬äºŒå¼ å›¾åƒ
        threshold (float): è‰²å·®é˜ˆå€¼
        brightness1 (float): ç¬¬ä¸€å¼ å›¾åƒçš„äº®åº¦
        contrast1 (float): ç¬¬ä¸€å¼ å›¾åƒçš„å¯¹æ¯”åº¦
        saturation1 (float): ç¬¬ä¸€å¼ å›¾åƒçš„é¥±å’Œåº¦
        brightness2 (float): ç¬¬äºŒå¼ å›¾åƒçš„äº®åº¦
        contrast2 (float): ç¬¬äºŒå¼ å›¾åƒçš„å¯¹æ¯”åº¦
        saturation2 (float): ç¬¬äºŒå¼ å›¾åƒçš„é¥±å’Œåº¦

        è¿”å›:
        tuple: æ ¹æ®è‰²å·®é˜ˆå€¼è¿”å›çš„å›¾åƒåŠå…¶å±æ€§
        """
        B, H, W, C = image1.shape
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        image1_tensor = image1.permute(0, 3, 1, 2).clone().to(device)
        image2_tensor = image2.permute(0, 3, 1, 2).clone().to(device)

        if image1.shape[1:] != image2.shape[1:]:
            image2_tensor = torch.nn.functional.interpolate(image2_tensor, size=(H, W), mode="bilinear")

        if image2.shape[0] < B:
            image2_tensor = image2_tensor[0].unsqueeze(0).repeat(B, 1, 1, 1)

        # è½¬æ¢ä¸ºnumpyæ ¼å¼å¹¶è®¡ç®—è‰²å·®
        image1_np = image1_tensor.permute(0, 2, 3, 1).cpu().numpy()[0]
        image2_np = image2_tensor.permute(0, 2, 3, 1).cpu().numpy()[0]

        # è®¡ç®—è‰²å·®
        color_diff = self.calculate_color_difference_in_diff_area(image1_np, image2_np)
        print(f"Color Difference in Difference Area: {color_diff}")
        

        # æ ¹æ®è‰²å·®é˜ˆå€¼åˆ¤æ–­å¹¶è¿”å›å¯¹åº”çš„å›¾åƒå’Œå±æ€§
        if color_diff < threshold:
            tensor_out = image1_tensor
            brightness = brightness1
            contrast = contrast1
            saturation = saturation1
        else:
            tensor_out = image2_tensor
            brightness = brightness2
            contrast = contrast2
            saturation = saturation2

        tensor_out = torch.clamp(tensor_out, 0, 1)
        tensor_out = tensor_out.permute(0, 2, 3, 1).cpu().float()

        return tensor_out, brightness, contrast, saturation, color_diff
    
    # A dictionary that contains all nodes you want to export with their names
    # NOTE: names should be globally unique,ä¸€è¡Œä¸éœ€è¦é€—å·ï¼Œå¤šè¡Œéœ€è¦é€—å·
    # å†’å·åä¸ºå‡½æ•°å
NODE_CLASS_MAPPINGS = {
    "Light or Dark": lightdarkjudgment
}

    # A dictionary that contains the friendly/humanly readable titles for the nodes
NODE_DISPLAY_NAME_MAPPINGS = {
    "Light or Dark": "Light or Dark"
    # After the colon is the name displayed on the node. Multiple lines correspond to multiple nodes
}
